---
title: "Using SpartanDB with Spartan R Package"
author: "Kieran Alden"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using SpartanDB with Spartan R Package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

spartanDB has been created to provide all additional requirements to link the sensitivity analysis techniques in the spartan package with a mysql database. This way, results from all sensitivity analyses experiments of a simulator are in one place, aiding transparency and reproducibility of generated statistical analyses, and increasing performance of the spartan package. Parameter value sets generated for sensitivity analyses can be added to the database. Results from executions of the simulator under those conditions can then be added to the database with reference to those paraeter sets and details of the experiment. This database functionality also aids mining of these simulation results for the machine learning emulation techniques that were introduced in spartan version 3. Similarly to spartan, we include detailed examples that show how parameter value sample sets are stored in the database, the results of executions under those conditions added, and analysed results produced by spartan stored alongside those experimental setups.

## Prerequisites
The following are required to run the spartanDB and spartan methods described here:

* The R statistical environment, version 2.13.1 or later.
* The spartanDB and spartan packages, downloaded from CRAN, and all dependent packages in the DESCRIPTION files of both packages
* The example simulation results, available from our laboratory website (www.ycil.org.uk)

## The case study
Out demonstration utilises data from our previously described agent-based lymphoid tissue development simulator (Patel et al., 2012; Alden et al., 2012). This is the same data on which the functionality of the spartan package was generated, and as such, we refer the reader to the vignettes for spartan for further detail of the case study. This vignette focuses on the link spartanDB provides between a mysql result storage system and the analysis methods provided by spartan

## Database Setup

SpartanDB assumes that a working mySQL installation exists on the machine upon which the package is being used, and that a database user is set up that has ALTER, CREATE, DELETE, DROP, INSERT, SELECT, and UPDATE privileges. A schema should be created in this database in which the tables created by spartanDB will be stored. A mySQL settings file is used to state the settings that should be used to connect to the database. The below is an example of such a settings file, which would connect to the schema spartan_db:

```bash
[spartan_db]
user=spartan_db_user
password=database_password
host=127.0.0.1
port=3306
database=spartan_db
```

A R script that connects to this database should then be initialised as follows
```{r, eval = FALSE}
library(RMySQL)
library(spartan)
# R needs a full path to find the settings file
rmysql.settingsfile<-["path_to_settings_file.cnf"]
rmysql.db<-"spartan_db"
dblink<-dbConnect(MySQL(),default.file=rmysql.settingsfile,group=rmysql.db)
```

SpartanDB then has methods for both creating and deleting the table structure the package requires. This needs to know the names of the parameters and responses of the simulator for which the results are being stored.

```{r, eval = FALSE}
parameters<-c("chemoThreshold","chemoUpperLinearAdjust","chemoLowerLinearAdjust","maxVCAMeffectProbabilityCutoff","vcamSlope")
measures<-c("Velocity","Displacement")
create_database_structure(dblink, parameters, measures)

delete_database_structure(dblink)
```

The dblink object created above will then be passed to each spartanDB function. At the end of the script, this connection should be closed:
```{r, eval = FALSE}
dbDisconnect(dblink)
```

## SpartanDB with Spartan Technique 2: Parameter Robustness

With the mysql database set up as detailed in the previous section, spartan can be used to create parameter value sets for a robustness analysis, which are stored in the database under a specified experiment. Once these are executed, functions are provided for adding these results to the database, associating these with the specified experiment, and then analysing these results to produce insights from this statistical analysis. Full detail of this analysis is not provided here, this would duplicate much of the information in the spartan vignettes. Instead, we refer the reader to the detail in the spartan package.

### Parameter Sampling

Parameter value sets are generated by specifying the parameter names, baseline/calibrated value, minimum and maximum value of the range being explored, and the increment value to apply in sampling.

```{r, eval=FALSE}
parameters<-c("chemoThreshold","chemoUpperLinearAdjust","chemoLowerLinearAdjust","maxVCAMeffectProbabilityCutoff","vcamSlope")
baseline<- c(0.3, 0.2, 0.04, 0.60, 1.0)
minvals <- c(0.10, 0.10, 0.015, 0.1, 0.25)
maxvals <- c(0.9, 0.50, 0.08, 1.0, 5.0)
incvals <- c(0.1, 0.05, 0.005, 0.05, 0.25)

# Experiment is created in the database by specifying an experiment description, such as that below. This will be created with the current date.
generate_robustness_set_in_db(dblink,parameters, baseline, minvals, maxvals, incvals, experiment_id=NULL, experiment_description="PPSim Robustness")
# If you wish, you can specify the date
generate_robustness_set_in_db(dblink,parameters, baseline, minvals, maxvals, incvals, experiment_id=NULL, experiment_description="PPSim Robustness", experiment_date="2018-09-03")
# If you have already established an experiment in the database and know the experiment ID (the primary key), you can also generate a parameter set for that experiment (though use of this method is unlikely)
generate_robustness_set_in_db(dblink,parameters, baseline, minvals, maxvals, incvals, experiment_id=2)

# You can then download this sample as a CSV file. Again you can do this using experiment_description and date, or by experiment ID
output_directory<-"/home/user/samples/"
download_sample_as_csvfile(output_directory, dblink, experiment_id=2)
```

In the case where a pre-generated sample already exists (as a CSV file for each parameter in this local sensitivity analysis case), spartanDB contains a method to add this to the database, creating a new experiment:

```{r,eval=FALSE}
parameter_set_path<-"/home/user/path_to_sample_csv_files"
add_existing_robustness_sample_to_database(dblink, parameter_set_path, parameters, experiment_description="Original PPSim Robustness")
# If you want to specify experiment date, you can do this with the experiment_date argument
```

A message will be returned stating that the parameter set has been added to the database, with a stated experiment ID.

### Parameter Analysis

## SpartanDB with Spartan Technique 3: Latin-hypercube analysis

Similarly to the above, methods are provided to generate sets of parameter values using a hypercube, and then produce and store the analysis of simulation executions run under those conditions. Again for full detail of the implementation of the technique, see the spartan vignettes.

### Parameter Sampling

Samples are generated by specifying the parameter names, minimum and maximum values of the range being explored, the number of sets to generate, and the sampling algorithm for the lhs package (either normal or optimal)

```{r,eval=FALSE}
parameters<-c("chemoThreshold","chemoUpperLinearAdjust","chemoLowerLinearAdjust","maxVCAMeffectProbabilityCutoff","vcamSlope")
number_samples<-500
minvals<-c(0.10, 0.10, 0.015, 0.1, 0.25)
maxvals<-c(0.9, 0.50, 0.08, 1.0, 5.0)
algorithm<-"normal"
# Experiment is created in the database by specifying an experiment description, such as that below. This will be created with the current date.
generate_lhc_set_in_db(dblink, parameters, number_samples, minvals, maxvals, algorithm, experiment_description="generated_lhc_set")
# If you wish, you can specify the date
generate_lhc_set_in_db(dblink, parameters, number_samples, minvals, maxvals, algorithm, experiment_description="generated_lhc_set", experiment_date="2018-09-03")
# If you have already established an experiment in the database and know the experiment ID (the primary key), you can also generate a parameter set for that experiment (though use of this method is unlikely)
generate_lhc_set_in_db(dblink, parameters, number_samples, minvals, maxvals, algorithm, experiment_id=2)

# You can then download this sample as a CSV file. Again you can do this using experiment_description and date, or by experiment ID
# In this case, the sample indicates which parameter of interest the sample is for
output_directory<-"/home/user/samples/"
download_sample_as_csvfile(output_directory, dblink, experiment_id=2)
```

In the case where a pre-generated sample already exists as a CSV file, spartanDB contains a method to add this to the database, creating a new experiment
```{r,eval=FALSE}
pre_generated_sample<-read.csv("/home/user/LHC_Params.csv",header=T)
add_existing_lhc_sample_to_database(dblink, pre_generated_sample, experiment_description="original ppsim lhc dataset")
# Again, if you want to specify a date for the experiment, you can do this with the experiment_date argument
```

### Parameter Analysis

## SpartanDB with Spartan Technique 4: Extended Fourier Amplitude Sampling Test (eFAST)

Methods are provided to generate sets of parameter values using the eFAST technique, and then produce and store the analysis of simulation executions run under those conditions. Again for full detail of the implementation of the technique, see the spartan vignettes.

### Parameter Sampling

Samples are generated by specifying the parameter names, minimum and maximum values of the range being explored, the number of samples to generate for each parameter, and the number of resample curves to employ.

```{r,eval=FALSE}
parameters<-c("chemoThreshold","chemoUpperLinearAdjust","chemoLowerLinearAdjust","maxVCAMeffectProbabilityCutoff","vcamSlope")
number_samples<-65
number_curves<-3
minvals<-c(0.10, 0.10, 0.015, 0.1, 0.25)
maxvals<-c(0.9, 0.50, 0.08, 1.0, 5.0)
# Experiment is created in the database by specifying an experiment description, such as that below. This will be created with the current date.
generate_efast_set_in_db(dblink, parameters, number_samples, minvals, maxvals, number_curves, experiment_description="PPSim eFAST")
# If you wish, you can specify the date
generate_efast_set_in_db(dblink, parameters, number_samples, minvals, maxvals, number_curves, experiment_description="PPSim eFAST", experiment_date="2018-09-03")
# If you have already established an experiment in the database and know the experiment ID (the primary key), you can also generate a parameter set for that experiment (though use of this method is unlikely)
generate_efast_set_in_db(dblink, parameters, number_samples, minvals, maxvals, number_curves, experiment_id=2)

# You can then download this sample as a CSV file. Again you can do this using experiment_description and date, or by experiment ID
# In this case, the sample indicates which parameter of interest and resample curve the sample is for
output_directory<-"/home/user/samples/"
download_sample_as_csvfile(output_directory, dblink, experiment_id=2)
```

Similarly to the methods above, if you have a pre-generated sample (one CSV file per parameter/curve pair) you can add this to the database:

```{r,eval=FALSE}
parameter_set_path<-"/home/user/path_to_sample_csv_files"
add_existing_efast_sample_to_database(dblink, parameter_set_path, parameters, num_curves, experiment_description="Original PPSim eFAST")
# Use the experiment_date option to specify the date of experiment if you don't want to use that day's date.
```

### Parameter Analysis

Vignettes are long form documentation commonly included in packages. Because they are part of the distribution of the package, they need to be as compact as possible. The `html_vignette` output type provides a custom style sheet (and tweaks some options) to ensure that the resulting html is as small as possible. The `html_vignette` format:

- Never uses retina figures
- Has a smaller default figure size
- Uses a custom CSS stylesheet instead of the default Twitter Bootstrap style

## Vignette Info

Note the various macros within the `vignette` section of the metadata block above. These are required in order to instruct R how to build the vignette. Note that you should change the `title` field and the `\VignetteIndexEntry` to match the title of your vignette.

## Styles

The `html_vignette` template includes a basic CSS theme. To override this theme you can specify your own CSS in the document metadata as follows:

    output: 
      rmarkdown::html_vignette:
        css: mystyles.css

## Figures

The figure sizes have been customised so that you can easily put two images side-by-side. 

```{r, fig.show='hold'}
plot(1:10)
plot(10:1)
```

You can enable figure captions by `fig_caption: yes` in YAML:

    output:
      rmarkdown::html_vignette:
        fig_caption: yes

Then you can use the chunk option `fig.cap = "Your figure caption."` in **knitr**.

## More Examples

You can write math expressions, e.g. $Y = X\beta + \epsilon$, footnotes^[A footnote here.], and tables, e.g. using `knitr::kable()`.

```{r, echo=FALSE, results='asis'}
knitr::kable(head(mtcars, 10))
```

Also a quote using `>`:

> "He who gives up [code] safety for [code] speed deserves neither."
([via](https://twitter.com/hadleywickham/status/504368538874703872))
